---
title: "Practical 1: Raw Read Data and Quality Control"
subtitle: "BIO511 Genomics - Command Line QC and Classification"
author: "Tor Kling"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    code-fold: false
    theme: cosmo
---

# Introduction

Next-generation sequencing (NGS) technologies generate millions of short DNA sequences called reads. You've already become quite familiar with Nanopore sequencing by this point, and are aware that NGS reads are error-prone. Hence it is essential that before we do any further sequence analysis, we first assess the quality of our read data using command line tools that provide both efficiency and reproducibility.

In this practical, we'll use command line tools to perform quality assessment and filtering, followed by taxonomic classification to understand what organisms are present in our samples. We will provide short-read files for you to use, as well as the code needed to perform the analyses. However, you will need to adapt paths and filenames to your own working environment, as well as select your own data and think about the biological significance of the results.

::: {.callout-important}
## REMEMBER: Create a separate project folder
```bash
# Make this practical directory in your home directory on HPC AND your local computer
mkdir -p ~/yourdir/practical_1
cd ~/yourdir/practical_1

# Then symlink the data directory in the n2bin-gu project dir for easy access on the HPC
ln -s  /cephyr/NOBACKUP/groups/n2bin_gu/BIO511/data/fastq ./data

# Copy the files you need to your local computer as well, but DONT overwrite the original files!
# You can use scp or rsync for this
scp -r CID@vera2.c3se.chalmers.se:/cephyr/NOBACKUP/groups/n2bin_gu/BIO511/data/fastq ./data

```
:::

::: {.callout-note}
## Learning Objectives

By the end of this practical, you will be able to:

- Understand the structure and format of raw sequencing data (FASTQ files)
- Use fastp for integrated quality assessment and filtering
- Interpret quality control metrics and HTML reports
- Apply quality trimming and adapter removal in a single step
- Perform taxonomic classification using kraken2 in a Singularity container
:::

---

# Understanding FASTQ Files

## Obtaining sample data

For this excersise, we offer a set of fastq file for you to Use
Begin by navigating to your symlinked data directory and look at the Files

You wont need to copy the files to your working directory, but make sure that any edits you make dont overwrite the original files! If you want you can also do this step on your local computer! 

## Examining FASTQ structure

```bash
# Look at the first few reads from a compressed file
# Use this code example for each of the sample files in the data dir
# Either untar the files first, or use zcat to read them directly
tar -xvzf sample1_R1.fastq.gz
cat sample1_R1.fastq | head -8

# or 
zcat sample1_R1.fastq.gz | head -8
```

Each sequencing read in a FASTQ file consists of four lines:

```
@read_identifier_and_description
ATCGATCGATCGATCG...
+
!"#$%&'()*+,-./0...
#########################DIVIDER#########################
```

::: {.callout-note}
## Key Questions
- Why is the bottom line encoded? What does it represent?
- How can you identify paired-end reads?
:::

---

# Quality Assessment and Filtering with fastp

fastp is a modern version of what FastQC used to do (in case youve used that before), it is an all-in-one preprocessing tool that combines quality assessment, adapter trimming, and quality filtering in a single program. Unlike the traditional FastQC + Trim Galore workflow, fastp provides integrated analysis with excellent performance. As you likely remember, we set up fastp on your computer locally last practical, so lets use it now. 

## Fastp analysis

This step must be done on your local computer, make sure you download the data with scp first! 

```bash
# Begin by creating an output directory for your QC results
mkdir -p fastp_results

# Run fastp on paired-end reads with default settings
fastp -i sample1_R1.fastq.gz -I sample1_R2.fastq.gz -o sample1_R1_filtered.fastq.gz -O sample1_R2_filtered.fastq.gz -h sample1_fastp_report.html -j sample1_fastp_report.json

# Go to the output directory and check the results
# View the HTML report in your browser 
```

Key metrics to examine in the HTML reports:

- **Read quality**: Before and after filtering quality distributions
- **Base content**: Per-position base composition
- **Adapter content**: Automatic adapter detection and removal
- **Filtering results**: Number of reads removed and why
- **Insert size**: The size of the DNA fragments sequenced (between the adapters and paired reads combined)

::: {.callout-note}
## Key Questions
1. What percentage of reads were filtered out in each sample?
2. What was the main reason for read filtering?
3. How did the quality distributions change after filtering?
4. Were any adapters detected and removed?
:::

In some cases, you may want to customize the filtering parameters, such as hard-trimming a specific number of bases from the start or end of reads, or setting a minimum read length. You can do this by adding additional flags to the fastp command. For example, a good agnostic approach is to trim to a fixed quality threshold at the 3' end of the reads, and filter out any reads that are too short after trimming.
```bash
# Here is an example command with additional trimming and filtering options, for a quality threshold of 30 and minimum length of 50bp
fastp -i sample1_R1.fastq.gz -I sample1_R2.fastq.gz -o sample1_R1_filtered.fastq.gz -O sample1_R2_filtered.fastq.gz -h sample1_fastp_report.html -j sample1_fastp_report.json --cut_right --cut_mean_quality 30 --length_required 20
```
::: {.callout-note}
## Key Questions
1. Did this improve or change the quality of the reads?
2. We set a minimum length of 20bp, what are the pros and cons of this choice?
:::

---

# Taxonomic Classification with kraken2

Now we'll classify our quality-filtered reads to identify what organisms are present in our samples. Classification of reads help us study the composition of DNA in our samples, useful both for cases like metagenomics, but also for contamination detection in our WGS samples.
We'll use the kraken2 container that you made in the previous practical. In case you havent put it up on the cluster yet, there is a copy available in the n2bin_gu group directory.


## HPC job script for kraken2 classification
Lets begin by creating the job script that we will submit to the HPC cluster. Make sure to adjust paths to your actual directories and database locations. You can either create and edit the file on the cluster, or create it locally and then upload it to the cluster if you want. ALso this jobscript will allow you to run a single sample at a time, so you will need to change the sample name for each run, or make a loop to run multiple samples if you feel up for it.

```bash
# Create SLURM job script for kraken2 analysis

#!/bin/bash
#SBATCH -A C3SE408-25-2
#SBATCH -J kraken2_job
#SBATCH -p vera
#SBATCH -N 1 --cpus-per-task=12 # Request 1 node with 12 CPUs
#SBATCH -t 01:00:00
#SBATCH --output=/cephyr/users/ktor/Vera/practical_1/logs/kraken2_%j.out  # Standard output
#SBATCH --error=/cephyr/users/ktor/Vera/practical_1/logs/kraken2_%j.err   # Standard error

# Set paths - ADJUST THESE TO YOUR ACTUAL PATHS
CONTAINER_PATH="/cephyr/NOBACKUP/groups/n2bin_gu/BIO511/singularity_images/kraken2.sif"
DB_PATH="/cephyr/NOBACKUP/groups/n2bin_gu/BIO511/ref_dbs/kraken2db"
DATA_PATH="/cephyr/NOBACKUP/groups/n2bin_gu/BIO511/data/fastq"
RESULTS_PATH="/cephyr/NOBACKUP/groups/n2bin_gu/teachers/Tor/results"

# Bind paths for container
export SINGULARITY_BINDPATH="${DB_PATH}:/db,${DATA_PATH}:/data,${RESULTS_PATH}:/results"

# Create results directory
mkdir -p ${RESULTS_PATH}

# Identify sample
sample="A210"
echo "Processing sample: ${sample}"

# Run Kraken2 classification
srun singularity exec ${CONTAINER_PATH} kraken2 \
        --db /db \
        --threads 8 \
        --paired \
        --output /results/${sample}_kraken2_output.txt \
        --report /results/${sample}_kraken2_report.txt \
        --classified-out /results/${sample}_classified#.fastq \
        --unclassified-out /results/${sample}_unclassified#.fastq \
        /data/${sample}_R1.fastq.gz /data/${sample}_R2.fastq.gz

echo "Completed classification for ${sample}"

echo "All samples processed successfully"
```

---

# Comprehensive Reporting with MultiQC

MultiQC is a powerful tool that aggregates results from multiple bioinformatics analyses into a single, interactive HTML report. It can automatically detect and parse outputs from fastp, kraken2, and many other tools, making it perfect for generating comprehensive summaries of our quality control and classification workflow.

## Preparing results for MultiQC

MultiQC works best when all results are organized in a clear directory structure. Let's organize our outputs properly.

```bash
# Create a comprehensive results directory
mkdir -p multiqc_analysis/{fastp_reports,kraken2_reports}

# Copy fastp outputs to the correct directory
# Copy kraken2 outputs to the correct directory

# Verify all files are present
ls -la multiqc_analysis/*/
```

## Running MultiQC

```bash
# Run MultiQC on all results to generate a comprehensive report
cd multiqc_analysis

# Generate MultiQC report with custom configuration
multiqc . --title "BIO511 Practical 2 - QC and Classification Summary" --filename "practical2_multiqc_report" --dirs --dirs-depth 2 --force

# Open the report in your browser
# The HTML file can be opened directly

```

---

# Additional exercises

Now that you have completed the quality control and classification workflow, use your fastp report, MultiQC report and command line tools to answer the following questions:

1. Which sample had the highest percentage of reads filtered out by fastp? What might this indicate about the sample quality?

2. Are there any concerning patterns in adapter content across samples? If so, which adapters were detected and in which samples?

3. What are the dominant taxa identified in each sample? Do the results make biological sense for your sample type?

4. Do any samples show signs of contamination or unexpected organisms? How would you investigate this further?

---

::: {.callout-note}
## Key Takeaways

- fastp provides integrated QC and filtering in a single, efficient tool
- Classification with kraken2 helps identify organisms in sequencing data, allowing for contamination detection (and metagenomic analysis)
- MultiQC creates nice reports by aggregating multiple tool outputs, it will likely make your PI very happy
- Always verify your results and create comprehensive summaries, as this is crucial for reproducibility and interpretation
:::

---
